"""
Dybdeanalyse av ML-v√¶rdata korrelasjoner for √• identifisere 
styrker og svakheter i ML-kriteriene.
"""

from datetime import datetime

import matplotlib.pyplot as plt
import pandas as pd


def analyze_ml_performance():
    """Analyser ML-ytelse i detalj"""

    print("üîç DYBDEANALYSE AV ML-YTELSE")
    print("=" * 40)

    # Last resultatene
    try:
        df = pd.read_csv('data/analyzed/ml_weather_correlation_analysis_20250811_2020.csv')
        print(f"‚úÖ Lastet {len(df)} episoder med ML-resultater")
    except Exception as e:
        print(f"‚ùå Kunne ikke laste ML-resultater: {e}")
        return

    # Grunnleggende statistikk
    print("\nüìä GRUNNLEGGENDE FUNN:")

    # Temperaturfordeling
    temp_stats = df['temperatur'].describe()
    print(f"Temperatur: {temp_stats['min']:.1f}¬∞C til {temp_stats['max']:.1f}¬∞C, median {temp_stats['50%']:.1f}¬∞C")

    # Vindfordeling
    vind_stats = df['vind'].describe()
    print(f"Vind: {vind_stats['min']:.1f} til {vind_stats['max']:.1f} m/s, median {vind_stats['50%']:.1f} m/s")

    # Sn√∏dybdefordeling
    sn√∏_stats = df['sn√∏dybde'].describe()
    print(f"Sn√∏dybde: {sn√∏_stats['min']:.1f} til {sn√∏_stats['max']:.1f} cm, median {sn√∏_stats['50%']:.1f} cm")

    # Nedb√∏rfordeling
    nedb√∏r_stats = df['nedb√∏r'].describe()
    print(f"Nedb√∏r: {nedb√∏r_stats['min']:.1f} til {nedb√∏r_stats['max']:.1f} mm, median {nedb√∏r_stats['50%']:.1f} mm")

    # Analyser ML-ytelse per kategori
    print("\nüéØ ML-YTELSE PER KATEGORI:")

    kategorier = ['heavy_plowing', 'standard_maintenance', 'road_inspection', 'friday_routine']

    for kategori in kategorier:
        kategori_data = df[df['kategori'] == kategori]
        if len(kategori_data) == 0:
            continue

        print(f"\n--- {kategori.upper()} ({len(kategori_data)} episoder) ---")

        # V√¶rforhold for denne kategorien
        print("Gjennomsnittlige v√¶rforhold:")
        print(f"  Temperatur: {kategori_data['temperatur'].mean():.1f}¬∞C")
        print(f"  Vind: {kategori_data['vind'].mean():.1f} m/s")
        print(f"  Sn√∏dybde: {kategori_data['sn√∏dybde'].mean():.1f} cm")
        print(f"  Nedb√∏r: {kategori_data['nedb√∏r'].mean():.1f} mm")

        # ML-risikoniv√•er
        sn√∏fokk_fordeling = kategori_data['sn√∏fokk_risiko'].value_counts()
        glattf√∏re_fordeling = kategori_data['glattf√∏re_risiko'].value_counts()

        print("ML-prediksjoner:")
        print(f"  Sn√∏fokk: {dict(sn√∏fokk_fordeling)}")
        print(f"  Glattf√∏re: {dict(glattf√∏re_fordeling)}")

        # Evaluer om ML-prediksjonen er rimelig
        if kategori in ['heavy_plowing', 'standard_maintenance']:
            # V√¶ravhengige - b√∏r ha medium/high risiko
            h√∏y_sn√∏fokk = len(kategori_data[kategori_data['sn√∏fokk_risiko'].isin(['medium', 'high'])])
            h√∏y_glattf√∏re = len(kategori_data[kategori_data['glattf√∏re_risiko'].isin(['medium', 'high'])])

            sn√∏fokk_andel = h√∏y_sn√∏fokk / len(kategori_data) * 100
            glattf√∏re_andel = h√∏y_glattf√∏re / len(kategori_data) * 100

            print(f"  H√∏y sn√∏fokk-risiko: {h√∏y_sn√∏fokk}/{len(kategori_data)} ({sn√∏fokk_andel:.1f}%)")
            print(f"  H√∏y glattf√∏re-risiko: {h√∏y_glattf√∏re}/{len(kategori_data)} ({glattf√∏re_andel:.1f}%)")

            if sn√∏fokk_andel >= 50 or glattf√∏re_andel >= 50:
                print("  ‚úÖ ML predikerer rimelig h√∏y risiko")
            else:
                print("  ‚ùå ML predikerer for lav risiko")
        else:
            # Ikke-v√¶ravhengige - b√∏r ha low risiko
            lav_sn√∏fokk = len(kategori_data[kategori_data['sn√∏fokk_risiko'] == 'low'])
            lav_glattf√∏re = len(kategori_data[kategori_data['glattf√∏re_risiko'] == 'low'])

            sn√∏fokk_andel = lav_sn√∏fokk / len(kategori_data) * 100
            glattf√∏re_andel = lav_glattf√∏re / len(kategori_data) * 100

            print(f"  Lav sn√∏fokk-risiko: {lav_sn√∏fokk}/{len(kategori_data)} ({sn√∏fokk_andel:.1f}%)")
            print(f"  Lav glattf√∏re-risiko: {lav_glattf√∏re}/{len(kategori_data)} ({glattf√∏re_andel:.1f}%)")

            if sn√∏fokk_andel >= 70 and glattf√∏re_andel >= 70:
                print("  ‚úÖ ML predikerer rimelig lav risiko")
            else:
                print("  ‚ö†Ô∏è ML predikerer for h√∏y risiko")

    # Identifiser problemer med ML-kriteriene
    print("\nüîç IDENTIFISERTE PROBLEMER:")

    # Problem 1: Glattf√∏re-risiko alltid lav
    h√∏y_glattf√∏re = len(df[df['glattf√∏re_risiko'].isin(['medium', 'high'])])
    if h√∏y_glattf√∏re == 0:
        print("‚ùå PROBLEM: Glattf√∏re-risiko er ALLTID 'low' - kriteriene er for strenge!")

    # Problem 2: Sn√∏fokk-risiko sjelden h√∏y
    h√∏y_sn√∏fokk = len(df[df['sn√∏fokk_risiko'] == 'high'])
    sn√∏fokk_prosent = h√∏y_sn√∏fokk / len(df) * 100
    if sn√∏fokk_prosent < 10:
        print(f"‚ö†Ô∏è PROBLEM: Sn√∏fokk 'high' risiko sjelden ({sn√∏fokk_prosent:.1f}%) - kanskje for strenge kriterier?")

    # Problem 3: V√¶ravhengige episoder med lav risiko
    v√¶ravhengige = df[df['er_v√¶ravhengig'] == True]
    lav_risiko_v√¶ravhengige = v√¶ravhengige[
        (v√¶ravhengige['sn√∏fokk_risiko'] == 'low') &
        (v√¶ravhengige['glattf√∏re_risiko'] == 'low')
    ]

    if len(lav_risiko_v√¶ravhengige) > len(v√¶ravhengige) * 0.3:
        prosent = len(lav_risiko_v√¶ravhengige) / len(v√¶ravhengige) * 100
        print(f"‚ö†Ô∏è PROBLEM: {prosent:.1f}% av v√¶ravhengige episoder har lav risiko - ML er for forsiktig!")

    # Forslag til forbedringer
    print("\nüí° FORSLAG TIL FORBEDRINGER:")

    if h√∏y_glattf√∏re == 0:
        print("1. GLATTF√òRE: Senk tersklene for glattf√∏re-risiko")
        print("   - N√•v√¶rende terskler er for strenge")
        print("   - Vurder √• inkludere flere faktorer (fuktighet, temperaturgradienter)")

    if sn√∏fokk_prosent < 10:
        print("2. SN√òFOKK: Juster sn√∏fokk-kriteriene")
        print("   - Vurder lavere vindterskler")
        print("   - Ta hensyn til sn√∏kvalitet og temperatur")

    # Spesifikke forbedringsforslag basert p√• data
    print("3. KALIBRERING: Basert p√• faktiske v√¶rforhold")

    # Analyser v√¶rforhold for v√¶ravhengige episoder som f√•r lav risiko
    if len(lav_risiko_v√¶ravhengige) > 0:
        print("   V√¶ravhengige episoder med lav ML-risiko har:")
        print(f"   - Snitt temperatur: {lav_risiko_v√¶ravhengige['temperatur'].mean():.1f}¬∞C")
        print(f"   - Snitt vind: {lav_risiko_v√¶ravhengige['vind'].mean():.1f} m/s")
        print(f"   - Snitt sn√∏dybde: {lav_risiko_v√¶ravhengige['sn√∏dybde'].mean():.1f} cm")
        print(f"   - Snitt nedb√∏r: {lav_risiko_v√¶ravhengige['nedb√∏r'].mean():.1f} mm")
        print("   ‚Üí Disse forholdene B√òR utl√∏se h√∏yere risiko!")


def create_visualization():
    """Lag visualiseringer av ML-ytelse"""

    try:
        df = pd.read_csv('data/analyzed/ml_weather_correlation_analysis_20250811_2020.csv')
    except Exception as e:
        print(f"‚ùå Kunne ikke lage visualisering: {e}")
        return

    plt.style.use('default')
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('ML-Ytelse Analyse: Br√∏yting vs V√¶rdata', fontsize=16, fontweight='bold')

    # 1. Temperatur vs ML-risiko
    ax1 = axes[0, 0]
    for risiko in ['low', 'medium', 'high']:
        subset = df[df['sn√∏fokk_risiko'] == risiko]
        if len(subset) > 0:
            ax1.scatter(subset['temperatur'], subset['vind'],
                       label=f'Sn√∏fokk {risiko}', alpha=0.7)
    ax1.set_xlabel('Temperatur (¬∞C)')
    ax1.set_ylabel('Vind (m/s)')
    ax1.set_title('Sn√∏fokk-risiko vs Temperatur/Vind')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # 2. Kategorier vs risiko
    ax2 = axes[0, 1]
    kategori_risiko = df.groupby(['kategori', 'sn√∏fokk_risiko']).size().unstack(fill_value=0)
    kategori_risiko.plot(kind='bar', ax=ax2, stacked=True)
    ax2.set_title('Sn√∏fokk-risiko per Kategori')
    ax2.set_xlabel('Kategori')
    ax2.set_ylabel('Antall episoder')
    ax2.tick_params(axis='x', rotation=45)

    # 3. V√¶ravhengighet vs ytelse
    ax3 = axes[1, 0]
    v√¶ravhengig_data = df.groupby(['er_v√¶ravhengig', 'sn√∏fokk_risiko']).size().unstack(fill_value=0)
    v√¶ravhengig_data.plot(kind='bar', ax=ax3)
    ax3.set_title('Sn√∏fokk-risiko: V√¶ravhengig vs Ikke-v√¶ravhengig')
    ax3.set_xlabel('V√¶ravhengig')
    ax3.set_ylabel('Antall episoder')
    ax3.tick_params(axis='x', rotation=0)

    # 4. V√¶rparametre fordeling
    ax4 = axes[1, 1]
    df_weather = df[['temperatur', 'vind', 'sn√∏dybde', 'nedb√∏r']].copy()
    # Normaliser for sammenligning
    df_weather['temperatur_norm'] = (df_weather['temperatur'] + 10) / 30  # Skaler til 0-1
    df_weather['vind_norm'] = df_weather['vind'] / 15  # Skaler til 0-1
    df_weather['sn√∏dybde_norm'] = df_weather['sn√∏dybde'] / 100  # Skaler til 0-1
    df_weather['nedb√∏r_norm'] = df_weather['nedb√∏r'] / 20  # Skaler til 0-1

    ax4.boxplot([df_weather['temperatur_norm'], df_weather['vind_norm'],
                 df_weather['sn√∏dybde_norm'], df_weather['nedb√∏r_norm']])
    ax4.set_xticklabels(['Temp', 'Vind', 'Sn√∏dybde', 'Nedb√∏r'])
    ax4.set_title('Normaliserte V√¶rparametre Fordeling')
    ax4.set_ylabel('Normalisert verdi (0-1)')
    ax4.grid(True, alpha=0.3)

    plt.tight_layout()

    # Lagre plot
    timestamp = datetime.now().strftime('%Y%m%d_%H%M')
    plot_file = f"data/graphs/ml_ytelse_analyse_{timestamp}.png"
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    print(f"üìä Visualisering lagret: {plot_file}")
    plt.close()


def main():
    """Kj√∏r dybdeanalyse av ML-ytelse"""

    print("üîç DYBDEANALYSE AV ML-V√ÜRDATA KORRELASJONER")
    print("=" * 55)

    analyze_ml_performance()

    print("\nüìä Lager visualiseringer...")
    create_visualization()

    print("\n‚úÖ DYBDEANALYSE FULLF√òRT")
    print("\nüéØ SAMMENDRAG:")
    print("Analysen identifiserer spesifikke problemer og forbedringsmuligheter")
    print("for ML-kriteriene basert p√• faktiske br√∏ytingsbeslutninger!")


if __name__ == "__main__":
    main()
